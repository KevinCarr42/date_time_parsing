{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ugly but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(dataframe, date_column, print_format=False):\n",
    "    if pd.api.types.is_datetime64_any_dtype(dataframe[date_column]):\n",
    "        return dataframe\n",
    "    \n",
    "    warnings.filterwarnings(\"error\")\n",
    "    date_formats = [\"%m/%d/%Y\", \"%m/%d/%y\", \"%Y/%m/%d\", \"%Y-%m-%d\"]\n",
    "    correct_format = False\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            dataframe[date_column] = pd.to_datetime(dataframe[date_column], format=date_format)\n",
    "            correct_format = True\n",
    "            if print_format:\n",
    "                print(date_format)\n",
    "        except (UserWarning, ValueError):\n",
    "            continue\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "    if not correct_format:\n",
    "        raise NotImplementedError('Correct date format not found.')\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required functions to crop csv files\n",
    "\n",
    "**METADATA at the bottom of the file, won't parse**:\n",
    "[data\\\\2017\\\\S010102_VOC_2017_EN.csv](data\\\\2017\\\\S010102_VOC_2017_EN.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_csv_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        for row in csv.reader(file):\n",
    "            for date_column in date_column_list:\n",
    "                if date_column in row:\n",
    "                    return num_rows_before_header, date_column\n",
    "            num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def csv_to_pandas(filepath, date_column_list=['Compounds', 'Sampling Date']):\n",
    "    num_rows_to_skip, date_column = how_many_csv_rows_to_skip(filepath, date_column_list)\n",
    "    parsed_data = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for _ in range(num_rows_to_skip):\n",
    "            next(reader)\n",
    "        \n",
    "        headers = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            if all(item == '' for item in row):\n",
    "                break\n",
    "            parsed_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(parsed_data, columns=headers)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing\n",
    "(plus some helper functions that may be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CHECK IMPORT SCRIPTS ARE WORKING ##################\n",
    "\n",
    "import openpyxl\n",
    "import os\n",
    "import xlrd\n",
    "import io\n",
    "\n",
    "ignore_list = [\n",
    "    'data\\\\ddmmyyyy.xlsx', 'data\\\\mmddyyyy.xlsx', 'data\\\\yyyyddmm.xlsx', 'data\\\\yyyymmdd.xlsx',\n",
    "    'data\\\\ddmmyyyy.csv', 'data\\\\mmddyyyy.csv', 'data\\\\yyyyddmm.csv', 'data\\\\yyyymmdd.csv',\n",
    "    'data\\\\2006\\\\S62601_VOCS.csv', 'data\\\\2007\\\\S62601_VOCS.csv',    # sideways csv for some reason\n",
    "    'data\\\\2008\\\\S90227_VOC.csv', 'data\\\\2009\\\\S90227_VOC.csv', 'data\\\\2010\\\\S90227_VOC.csv',  # sampling data relocated\n",
    "    'data\\\\2015\\\\ChangeLog_Jan2017.xls'\n",
    "]\n",
    "\n",
    "\n",
    "def how_many_csv_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        for row in csv.reader(file):\n",
    "            for date_column in date_column_list:\n",
    "                if date_column in row:\n",
    "                    return num_rows_before_header, date_column\n",
    "            num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def how_many_xlsx_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, \"rb\") as f:  # fucking malloc\n",
    "        in_mem_file = io.BytesIO(f.read())\n",
    "    wb = openpyxl.load_workbook(in_mem_file, read_only=True)\n",
    "\n",
    "    sheet = None\n",
    "    for name in wb.sheetnames:\n",
    "        if 'voc' in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "        if 'data' in name.lower() and 'metadata' not in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                return num_rows_before_header, date_column, name\n",
    "        num_rows_before_header += 1\n",
    "       \n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def get_xls_sheet(workbook):\n",
    "    for name in workbook.sheet_names():\n",
    "        if 'voc' in name.lower():\n",
    "            return workbook[name], name\n",
    "        elif 'data' in name.lower():\n",
    "            return workbook[name], name\n",
    "    return workbook.sheet_by_index(0), 0\n",
    "\n",
    "\n",
    "def how_many_xls_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "    wb = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "\n",
    "    sheet, name = get_xls_sheet(wb)\n",
    "\n",
    "    for row_idx in range(sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                return num_rows_before_header, date_column, name\n",
    "        num_rows_before_header += 1\n",
    "\n",
    "    wb.close()\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def try_all_imports(skip_xls=False, skip_xlsx=False, skip_csv=False, ignore_list=None, filter_warnings=False):\n",
    "    if filter_warnings:\n",
    "        warnings.filterwarnings(\"error\")\n",
    "    n_errors, n_files, n_xls, n_xlsx, n_csv, n_xls_complete, n_xlsx_complete, n_csv_complete  = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    error_list = list()\n",
    "\n",
    "    for root, dirs, files in os.walk('data'):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            if filepath in ignore_list:\n",
    "                continue\n",
    "\n",
    "            extension = filepath.split('.')[-1].lower()\n",
    "            if skip_xls and extension == 'xls':\n",
    "                continue\n",
    "            elif skip_xlsx and extension == 'xlsx':\n",
    "                continue\n",
    "            elif skip_csv and extension == 'csv':\n",
    "                continue\n",
    "            elif extension not in ['xls', 'xlsx', 'csv']:\n",
    "                continue\n",
    "\n",
    "            name = filepath.split('.')[0].lower()\n",
    "            if name[-2:].lower() == 'fr':\n",
    "                continue\n",
    "            else:\n",
    "                n_files += 1\n",
    "                try:\n",
    "                    if extension == 'xls':\n",
    "                        n_xls += 1\n",
    "                        header, date_column, sheet_name = how_many_xls_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        workbook = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "                        dataframe = pd.read_excel(workbook, header=header, sheet_name=sheet_name, engine='xlrd')\n",
    "                        parse_dates(dataframe, date_column=date_column)\n",
    "                        n_xls_complete += 1\n",
    "                    elif extension == 'xlsx':\n",
    "                        n_xlsx += 1\n",
    "                        header, date_column, sheet_name = how_many_xlsx_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        parse_dates(pd.read_excel(filepath, header=header, sheet_name=sheet_name), date_column=date_column)\n",
    "                        n_xlsx_complete += 1\n",
    "                    elif extension == 'csv':\n",
    "                        n_csv += 1\n",
    "                        header, date_column = how_many_csv_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        parse_dates(csv_to_pandas(filepath), date_column=date_column)\n",
    "                        n_csv_complete += 1\n",
    "                except:\n",
    "                    n_errors += 1\n",
    "                    error_list.append(filepath)\n",
    "                    \n",
    "    if filter_warnings:\n",
    "        warnings.resetwarnings()\n",
    "\n",
    "    print(f'{n_errors} errors / {n_files} total files')\n",
    "    print(f'xls: {n_xls_complete} out of {n_xls}')\n",
    "    print(f'csv: {n_csv_complete} out of {n_csv}')\n",
    "    print(f'xlsx: {n_xlsx_complete} out of {n_xlsx}')\n",
    "\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLSX\n",
    "* seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 118 total files\n",
      "xls: 0 out of 0\n",
      "csv: 0 out of 0\n",
      "xlsx: 118 out of 118\n"
     ]
    }
   ],
   "source": [
    "xlsx_errors = try_all_imports(skip_xls=True, skip_xlsx=False, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLS\n",
    "* seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 220 total files\n",
      "xls: 220 out of 220\n",
      "csv: 0 out of 0\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "xls_errors = try_all_imports(skip_xls=False, skip_xlsx=True, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 628 total files\n",
      "xls: 0 out of 0\n",
      "csv: 628 out of 628\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "csv_errors = try_all_imports(skip_xls=True, skip_xlsx=True, skip_csv=False, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
