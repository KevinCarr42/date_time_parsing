{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import openpyxl\n",
    "import os\n",
    "import xlrd\n",
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "from openpyxl.utils.datetime import from_excel as datetime_from_excel\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "################## CSV ##################\n",
    "\n",
    "def how_many_csv_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        for row in csv.reader(file):\n",
    "            for date_column in date_column_list:\n",
    "                if date_column in row:\n",
    "                    return num_rows_before_header, date_column\n",
    "            num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def csv_to_pandas(filepath, date_column_list=['Compounds', 'Sampling Date']):\n",
    "    num_rows_to_skip, date_column = how_many_csv_rows_to_skip(filepath, date_column_list)\n",
    "    parsed_data = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for _ in range(num_rows_to_skip):\n",
    "            next(reader)\n",
    "        \n",
    "        headers = next(reader)\n",
    "        date_column_index = headers.index(date_column)\n",
    "        \n",
    "        for row in reader:\n",
    "            if all(item == '' for item in row):\n",
    "                break\n",
    "            row[date_column_index] = parser.parse(row[date_column_index])\n",
    "            parsed_data.append(row)\n",
    "\n",
    "    return pd.DataFrame(parsed_data, columns=headers)\n",
    "\n",
    "\n",
    "################## XLSX ##################\n",
    "\n",
    "def how_many_xlsx_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "    wb = openpyxl.load_workbook(filepath, read_only=True)\n",
    "\n",
    "    sheet = None\n",
    "    for name in wb.sheetnames:\n",
    "        if 'voc' in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "        if 'data' in name.lower() and 'metadata' not in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                wb.close()\n",
    "                return num_rows_before_header, date_column\n",
    "        num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def xlsx_to_pandas(filepath, date_column_list=['Compounds', 'Sampling Date']):\n",
    "    num_rows_to_skip, date_column = how_many_xlsx_rows_to_skip(filepath, date_column_list)\n",
    "    wb = openpyxl.load_workbook(filepath)\n",
    "\n",
    "    sheet = None\n",
    "    for name in wb.sheetnames:\n",
    "        if 'voc' in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "        if 'data' in name.lower() and 'metadata' not in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "\n",
    "    for _ in range(num_rows_to_skip):\n",
    "        next(sheet.iter_rows())\n",
    "\n",
    "    header_row = next(sheet.iter_rows(min_row=sheet.min_row + num_rows_to_skip, max_row=sheet.min_row + num_rows_to_skip, values_only=True))\n",
    "    date_column_index = header_row.index(date_column) if date_column in header_row else None\n",
    "\n",
    "    parsed_data = []\n",
    "    for row in sheet.iter_rows(min_row=sheet.min_row + num_rows_to_skip + 1, values_only=True):\n",
    "        row = list(row)  # Convert the tuple to a list for modification\n",
    "\n",
    "        date_cell = row[date_column_index]\n",
    "        if isinstance(date_cell, datetime):\n",
    "            pass\n",
    "        elif isinstance(date_cell, float):\n",
    "            row[date_column_index] = datetime_from_excel(date_cell)\n",
    "        elif date_cell:\n",
    "            row[date_column_index] = parser.parse(date_cell)\n",
    "            \n",
    "        parsed_data.append(row)\n",
    "\n",
    "    return pd.DataFrame(parsed_data, columns=header_row)\n",
    "\n",
    "\n",
    "################## XLS ##################\n",
    "\n",
    "def get_xls_sheet(workbook):\n",
    "    for name in workbook.sheet_names():\n",
    "        if 'voc' in name.lower():\n",
    "            return workbook[name]\n",
    "        elif 'data' in name.lower():\n",
    "            return workbook[name]\n",
    "    return workbook.sheet_by_index(0)\n",
    "\n",
    "\n",
    "def how_many_xls_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "    wb = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "    \n",
    "    sheet = get_xls_sheet(wb)\n",
    "\n",
    "    for row_idx in range(sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                return num_rows_before_header, date_column\n",
    "        num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def xls_to_pandas(filepath, date_column_list=['Compounds', 'Sampling Date']):\n",
    "    num_rows_to_skip, date_column = how_many_xls_rows_to_skip(filepath, date_column_list)\n",
    "    wb = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "\n",
    "    sheet = get_xls_sheet(wb)\n",
    "\n",
    "    header_row = None\n",
    "    for row_idx in range(num_rows_to_skip, sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "        if date_column in row:\n",
    "            header_row = row\n",
    "            num_rows_to_skip = row_idx\n",
    "            break\n",
    "\n",
    "    date_column_index = header_row.index(date_column)\n",
    "\n",
    "    parsed_data = []\n",
    "    for row_idx in range(num_rows_to_skip + 1, sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "        row[date_column_index] = xlrd.xldate_as_datetime(row[date_column_index], wb.datemode)\n",
    "        parsed_data.append(row)\n",
    "\n",
    "    return pd.DataFrame(parsed_data, columns=header_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CHECK IMPORT SCRIPTS ARE WORKING ##################\n",
    "\n",
    "def check_all_imports(skip_xls=False, skip_xlsx=False, skip_csv=False, ignore_list=None):\n",
    "    n_errors, n_files, n_xls, n_xlsx, n_csv, n_xls_complete, n_xlsx_complete, n_csv_complete  = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    error_list = list()\n",
    "\n",
    "    for root, dirs, files in os.walk('data'):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            if filepath in ignore_list:\n",
    "                continue\n",
    "\n",
    "            extension = filepath.split('.')[-1].lower()\n",
    "            if skip_xls and extension == 'xls':\n",
    "                continue\n",
    "            elif skip_xlsx and extension == 'xlsx':\n",
    "                continue\n",
    "            elif skip_csv and extension == 'csv':\n",
    "                continue\n",
    "            elif extension not in ['xls', 'xlsx', 'csv']:\n",
    "                continue\n",
    "\n",
    "            n_files += 1\n",
    "            name = filepath.split('.')[0].lower()\n",
    "            if name[-2:].lower() == 'fr':\n",
    "                continue\n",
    "            else:\n",
    "                try:\n",
    "                    if extension == 'xls':\n",
    "                        n_xls += 1\n",
    "                        xls_to_pandas(filepath)\n",
    "                        n_xls_complete += 1\n",
    "                    elif extension == 'xlsx':\n",
    "                        n_xlsx += 1\n",
    "                        xlsx_to_pandas(filepath)\n",
    "                        n_xlsx_complete += 1\n",
    "                    elif extension == 'csv':\n",
    "                        n_csv += 1\n",
    "                        csv_to_pandas(filepath)\n",
    "                        n_csv_complete += 1\n",
    "                except:\n",
    "                    n_errors += 1\n",
    "                    error_list.append(filepath)\n",
    "\n",
    "    print(f'{n_errors} errors / {n_files} total files')\n",
    "    print(f'xls: {n_xls_complete} out of {n_xls}')\n",
    "    print(f'csv: {n_csv_complete} out of {n_csv}')\n",
    "    print(f'xlsx: {n_xlsx_complete} out of {n_xlsx}')\n",
    "\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_list = [\n",
    "    'data\\\\ddmmyyyy.xlsx', 'data\\\\mmddyyyy.xlsx', 'data\\\\yyyyddmm.xlsx', 'data\\\\yyyymmdd.xlsx',\n",
    "    'data\\\\ddmmyyyy.csv', 'data\\\\mmddyyyy.csv', 'data\\\\yyyyddmm.csv', 'data\\\\yyyymmdd.csv',\n",
    "    'data\\\\2006\\\\S62601_VOCS.csv', 'data\\\\2007\\\\S62601_VOCS.csv',    # sideways csv for some reason\n",
    "    'data\\\\2008\\\\S90227_VOC.csv', 'data\\\\2009\\\\S90227_VOC.csv', 'data\\\\2010\\\\S90227_VOC.csv',  # sampling data relocated\n",
    "    'data\\\\2015\\\\ChangeLog_Jan2017.xls'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLSX works (or seems to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 236 total files\n",
      "xls: 0 out of 0\n",
      "csv: 0 out of 0\n",
      "xlsx: 118 out of 118\n"
     ]
    }
   ],
   "source": [
    "xlsx_errors = check_all_imports(skip_xls=True, skip_xlsx=False, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV works (finally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 786 total files\n",
      "xls: 0 out of 0\n",
      "csv: 628 out of 628\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "csv_errors = check_all_imports(skip_xls=True, skip_xlsx=True, skip_csv=False, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLS works too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 260 total files\n",
      "xls: 220 out of 220\n",
      "csv: 0 out of 0\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "xls_errors = check_all_imports(skip_xls=False, skip_xlsx=True, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Confirm everything works correctly with random inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = list()\n",
    "for root, dirs, files in os.walk('data'):\n",
    "    for filename in files:\n",
    "        filepath = os.path.join(root, filename)\n",
    "        if filepath not in ignore_list:\n",
    "            list_of_files.append(filepath)\n",
    "\n",
    "list_of_files = [x for x in list_of_files if x not in ignore_list]\n",
    "list_of_files = [x for x in list_of_files if x.split('.')[-2][-2:].lower() != 'fr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\\2018\\S101005_VOC_2018_EN.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAPS ID</th>\n",
       "      <th>Sampling Date</th>\n",
       "      <th>Sample Type</th>\n",
       "      <th>Ethylene</th>\n",
       "      <th>Ethylene-MDL</th>\n",
       "      <th>Ethylene-VFlag</th>\n",
       "      <th>Acetylene</th>\n",
       "      <th>Acetylene-MDL</th>\n",
       "      <th>Acetylene-VFlag</th>\n",
       "      <th>Ethane</th>\n",
       "      <th>...</th>\n",
       "      <th>1,2,4-Trichlorobenzene-VFlag</th>\n",
       "      <th>Naphthalene</th>\n",
       "      <th>Naphthalene-MDL</th>\n",
       "      <th>Naphthalene-VFlag</th>\n",
       "      <th>Dodecane</th>\n",
       "      <th>Dodecane-MDL</th>\n",
       "      <th>Dodecane-VFlag</th>\n",
       "      <th>Hexachlorobutadiene</th>\n",
       "      <th>Hexachlorobutadiene-MDL</th>\n",
       "      <th>Hexachlorobutadiene-VFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101005</td>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>R</td>\n",
       "      <td>1.3474999999999999</td>\n",
       "      <td>0.1</td>\n",
       "      <td></td>\n",
       "      <td>0.67098999999999998</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "      <td>3.4742999999999999</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>3.5942000000000002E-2</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "      <td>2.0506E-2</td>\n",
       "      <td>0.1</td>\n",
       "      <td></td>\n",
       "      <td>4.8830000000000002E-3</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101005</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>R</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101005</td>\n",
       "      <td>2018-01-14</td>\n",
       "      <td>R</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2.9961000000000002E-2</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "      <td>7.4539999999999997E-3</td>\n",
       "      <td>0.1</td>\n",
       "      <td></td>\n",
       "      <td>3.764E-3</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101005</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>R</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101005</td>\n",
       "      <td>2018-01-26</td>\n",
       "      <td>R</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>-999</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1.2833000000000001E-2</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "      <td>5.6030000000000003E-3</td>\n",
       "      <td>0.1</td>\n",
       "      <td></td>\n",
       "      <td>3.1679999999999998E-3</td>\n",
       "      <td>0.2</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  NAPS ID Sampling Date Sample Type            Ethylene Ethylene-MDL   \n",
       "0  101005    2018-01-02           R  1.3474999999999999          0.1  \\\n",
       "1  101005    2018-01-08           R                -999         -999   \n",
       "2  101005    2018-01-14           R                -999         -999   \n",
       "3  101005    2018-01-20           R                -999         -999   \n",
       "4  101005    2018-01-26           R                -999         -999   \n",
       "\n",
       "  Ethylene-VFlag            Acetylene Acetylene-MDL Acetylene-VFlag   \n",
       "0                 0.67098999999999998           0.2                  \\\n",
       "1             M1                 -999          -999              M1   \n",
       "2             M1                 -999          -999              M1   \n",
       "3             M1                 -999          -999              M1   \n",
       "4             M1                 -999          -999              M1   \n",
       "\n",
       "               Ethane  ... 1,2,4-Trichlorobenzene-VFlag   \n",
       "0  3.4742999999999999  ...                               \\\n",
       "1                -999  ...                           M1   \n",
       "2                -999  ...                                \n",
       "3                -999  ...                           M1   \n",
       "4                -999  ...                                \n",
       "\n",
       "             Naphthalene Naphthalene-MDL Naphthalene-VFlag   \n",
       "0  3.5942000000000002E-2             0.2                    \\\n",
       "1                   -999            -999                M1   \n",
       "2  2.9961000000000002E-2             0.2                     \n",
       "3                   -999            -999                M1   \n",
       "4  1.2833000000000001E-2             0.2                     \n",
       "\n",
       "                Dodecane Dodecane-MDL Dodecane-VFlag    Hexachlorobutadiene   \n",
       "0              2.0506E-2          0.1                 4.8830000000000002E-3  \\\n",
       "1                   -999         -999             M1                   -999   \n",
       "2  7.4539999999999997E-3          0.1                              3.764E-3   \n",
       "3                   -999         -999             M1                   -999   \n",
       "4  5.6030000000000003E-3          0.1                 3.1679999999999998E-3   \n",
       "\n",
       "  Hexachlorobutadiene-MDL Hexachlorobutadiene-VFlag  \n",
       "0                     0.2                            \n",
       "1                    -999                        M1  \n",
       "2                     0.2                            \n",
       "3                    -999                        M1  \n",
       "4                     0.2                            \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "NAPS ID                              object\n",
       "Sampling Date                datetime64[ns]\n",
       "Sample Type                          object\n",
       "Ethylene                             object\n",
       "Ethylene-MDL                         object\n",
       "                                  ...      \n",
       "Dodecane-MDL                         object\n",
       "Dodecane-VFlag                       object\n",
       "Hexachlorobutadiene                  object\n",
       "Hexachlorobutadiene-MDL              object\n",
       "Hexachlorobutadiene-VFlag            object\n",
       "Length: 330, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "file = random.choice(list_of_files)\n",
    "print(file)\n",
    "extension = file.split('.')[-1].lower()\n",
    "\n",
    "df = None\n",
    "if extension == 'xls':\n",
    "    df = xls_to_pandas(file)\n",
    "elif extension == 'xlsx':\n",
    "    df = xlsx_to_pandas(file)\n",
    "elif extension == 'csv':\n",
    "    df = csv_to_pandas(file)\n",
    "else:\n",
    "    print('NO EXTENSION')\n",
    "\n",
    "if isinstance(df, pd.DataFrame):\n",
    "    display(df.head())\n",
    "    display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
