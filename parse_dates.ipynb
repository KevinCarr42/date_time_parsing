{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ugly but it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(dataframe, date_column, print_format=False):\n",
    "    if pd.api.types.is_datetime64_any_dtype(dataframe[date_column]):\n",
    "        return dataframe\n",
    "    \n",
    "    warnings.filterwarnings(\"error\")\n",
    "    date_formats = [\"%m/%d/%Y\", \"%m/%d/%y\", \"%Y/%m/%d\", \"%Y-%m-%d\"]\n",
    "    correct_format = False\n",
    "    for date_format in date_formats:\n",
    "        try:\n",
    "            dataframe[date_column] = pd.to_datetime(dataframe[date_column], format=date_format)\n",
    "            correct_format = True\n",
    "            if print_format:\n",
    "                print(date_format)\n",
    "        except (UserWarning, ValueError):\n",
    "            continue\n",
    "\n",
    "    warnings.resetwarnings()\n",
    "    if not correct_format:\n",
    "        raise NotImplementedError('Correct date format not found.')\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required functions to crop csv files\n",
    "\n",
    "**METADATA at the bottom of the file, won't parse**:\n",
    "[data\\\\2017\\\\S010102_VOC_2017_EN.csv](data\\\\2017\\\\S010102_VOC_2017_EN.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_csv_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        for row in csv.reader(file):\n",
    "            for date_column in date_column_list:\n",
    "                if date_column in row:\n",
    "                    return num_rows_before_header, date_column\n",
    "            num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def csv_to_pandas(filepath, date_column_list=['Compounds', 'Sampling Date']):\n",
    "    num_rows_to_skip, date_column = how_many_csv_rows_to_skip(filepath, date_column_list)\n",
    "    parsed_data = []\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for _ in range(num_rows_to_skip):\n",
    "            next(reader)\n",
    "        \n",
    "        headers = next(reader)\n",
    "        \n",
    "        for row in reader:\n",
    "            if all(item == '' for item in row):\n",
    "                break\n",
    "            parsed_data.append(row)\n",
    "\n",
    "    df = pd.DataFrame(parsed_data, columns=headers)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing\n",
    "(plus some helper functions that may be useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "################## CHECK IMPORT SCRIPTS ARE WORKING ##################\n",
    "\n",
    "import openpyxl\n",
    "import os\n",
    "import xlrd\n",
    "import io\n",
    "\n",
    "\n",
    "ignore_list = [\n",
    "    'data\\\\ddmmyyyy.xlsx', 'data\\\\mmddyyyy.xlsx', 'data\\\\yyyyddmm.xlsx', 'data\\\\yyyymmdd.xlsx',\n",
    "    'data\\\\ddmmyyyy.csv', 'data\\\\mmddyyyy.csv', 'data\\\\yyyyddmm.csv', 'data\\\\yyyymmdd.csv',\n",
    "    'data\\\\2006\\\\S62601_VOCS.csv', 'data\\\\2007\\\\S62601_VOCS.csv',    # sideways csv for some reason\n",
    "    'data\\\\2008\\\\S90227_VOC.csv', 'data\\\\2009\\\\S90227_VOC.csv', 'data\\\\2010\\\\S90227_VOC.csv',  # sampling data relocated\n",
    "    'data\\\\2015\\\\ChangeLog_Jan2017.xls'\n",
    "]\n",
    "\n",
    "\n",
    "def how_many_csv_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, 'r', encoding='ISO-8859-1') as file:\n",
    "        for row in csv.reader(file):\n",
    "            for date_column in date_column_list:\n",
    "                if date_column in row:\n",
    "                    return num_rows_before_header, date_column\n",
    "            num_rows_before_header += 1\n",
    "\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def how_many_xlsx_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "\n",
    "    with open(filepath, \"rb\") as f:  # fucking malloc\n",
    "        in_mem_file = io.BytesIO(f.read())\n",
    "    wb = openpyxl.load_workbook(in_mem_file, read_only=True)\n",
    "\n",
    "    sheet = None\n",
    "    for name in wb.sheetnames:\n",
    "        if 'voc' in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "        if 'data' in name.lower() and 'metadata' not in name.lower():\n",
    "            sheet = wb[name]\n",
    "            break\n",
    "\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                return num_rows_before_header, date_column, name\n",
    "        num_rows_before_header += 1\n",
    "       \n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def get_xls_sheet(workbook):\n",
    "    for name in workbook.sheet_names():\n",
    "        if 'voc' in name.lower():\n",
    "            return workbook[name], name\n",
    "        elif 'data' in name.lower():\n",
    "            return workbook[name], name\n",
    "    return workbook.sheet_by_index(0), 0\n",
    "\n",
    "\n",
    "def how_many_xls_rows_to_skip(filepath, date_column_list):\n",
    "    num_rows_before_header = 0\n",
    "    wb = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "\n",
    "    sheet, name = get_xls_sheet(wb)\n",
    "\n",
    "    for row_idx in range(sheet.nrows):\n",
    "        row = sheet.row_values(row_idx)\n",
    "        for date_column in date_column_list:\n",
    "            if date_column in row:\n",
    "                return num_rows_before_header, date_column, name\n",
    "        num_rows_before_header += 1\n",
    "\n",
    "    wb.close()\n",
    "\n",
    "    return None, None, None\n",
    "\n",
    "\n",
    "def try_all_imports(skip_xls=False, skip_xlsx=False, skip_csv=False, ignore_list=[None], filter_warnings=False):\n",
    "    if filter_warnings:\n",
    "        warnings.filterwarnings(\"error\")\n",
    "    n_errors, n_files, n_xls, n_xlsx, n_csv, n_xls_complete, n_xlsx_complete, n_csv_complete  = 0, 0, 0, 0, 0, 0, 0, 0\n",
    "    error_list = list()\n",
    "\n",
    "    for root, dirs, files in os.walk('data'):\n",
    "        for filename in files:\n",
    "            filepath = os.path.join(root, filename)\n",
    "            if filepath in ignore_list:\n",
    "                continue\n",
    "\n",
    "            extension = filepath.split('.')[-1].lower()\n",
    "            if skip_xls and extension == 'xls':\n",
    "                continue\n",
    "            elif skip_xlsx and extension == 'xlsx':\n",
    "                continue\n",
    "            elif skip_csv and extension == 'csv':\n",
    "                continue\n",
    "            elif extension not in ['xls', 'xlsx', 'csv']:\n",
    "                continue\n",
    "\n",
    "            name = filepath.split('.')[0].lower()\n",
    "            if name[-2:].lower() == 'fr':\n",
    "                continue\n",
    "            else:\n",
    "                n_files += 1\n",
    "                try:\n",
    "                    if extension == 'xls':\n",
    "                        n_xls += 1\n",
    "                        header, date_column, sheet_name = how_many_xls_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        workbook = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "                        dataframe = pd.read_excel(workbook, header=header, sheet_name=sheet_name, engine='xlrd')\n",
    "                        parse_dates(dataframe, date_column=date_column)\n",
    "                        n_xls_complete += 1\n",
    "                    elif extension == 'xlsx':\n",
    "                        n_xlsx += 1\n",
    "                        header, date_column, sheet_name = how_many_xlsx_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        parse_dates(pd.read_excel(filepath, header=header, sheet_name=sheet_name), date_column=date_column)\n",
    "                        n_xlsx_complete += 1\n",
    "                    elif extension == 'csv':\n",
    "                        n_csv += 1\n",
    "                        header, date_column = how_many_csv_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "                        parse_dates(csv_to_pandas(filepath), date_column=date_column)\n",
    "                        n_csv_complete += 1\n",
    "                except:\n",
    "                    n_errors += 1\n",
    "                    error_list.append(filepath)\n",
    "                    \n",
    "    if filter_warnings:\n",
    "        warnings.resetwarnings()\n",
    "\n",
    "    print(f'{n_errors} errors / {n_files} total files')\n",
    "    print(f'xls: {n_xls_complete} out of {n_xls}')\n",
    "    print(f'csv: {n_csv_complete} out of {n_csv}')\n",
    "    print(f'xlsx: {n_xlsx_complete} out of {n_xlsx}')\n",
    "\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLSX\n",
    "* seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 118 total files\n",
      "xls: 0 out of 0\n",
      "csv: 0 out of 0\n",
      "xlsx: 118 out of 118\n"
     ]
    }
   ],
   "source": [
    "xlsx_errors = try_all_imports(skip_xls=True, skip_xlsx=False, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### XLS\n",
    "* seems to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 220 total files\n",
      "xls: 220 out of 220\n",
      "csv: 0 out of 0\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "xls_errors = try_all_imports(skip_xls=False, skip_xlsx=True, skip_csv=True, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 errors / 628 total files\n",
      "xls: 0 out of 0\n",
      "csv: 628 out of 628\n",
      "xlsx: 0 out of 0\n"
     ]
    }
   ],
   "source": [
    "csv_errors = try_all_imports(skip_xls=True, skip_xlsx=True, skip_csv=False, ignore_list=ignore_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Random Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def pick_random_file(directory, ignore_list):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(root, file)\n",
    "            if (file.split('.')[0].lower()[-2:] != 'fr') and (filepath not in ignore_list):\n",
    "                all_files.append(os.path.join(root, file))\n",
    "\n",
    "    return random.choice(all_files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NAPS ID                               int64\n",
       "Sampling Date                datetime64[ns]\n",
       "Sample Type                          object\n",
       "Ethylene                            float64\n",
       "Ethylene-MDL                        float64\n",
       "                                  ...      \n",
       "Dodecane-MDL                        float64\n",
       "Dodecane-VFlag                       object\n",
       "Hexachlorobutadiene                 float64\n",
       "Hexachlorobutadiene-MDL             float64\n",
       "Hexachlorobutadiene-VFlag            object\n",
       "Length: 330, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NAPS ID</th>\n",
       "      <th>Sampling Date</th>\n",
       "      <th>Sample Type</th>\n",
       "      <th>Ethylene</th>\n",
       "      <th>Ethylene-MDL</th>\n",
       "      <th>Ethylene-VFlag</th>\n",
       "      <th>Acetylene</th>\n",
       "      <th>Acetylene-MDL</th>\n",
       "      <th>Acetylene-VFlag</th>\n",
       "      <th>Ethane</th>\n",
       "      <th>...</th>\n",
       "      <th>1,2,4-Trichlorobenzene-VFlag</th>\n",
       "      <th>Naphthalene</th>\n",
       "      <th>Naphthalene-MDL</th>\n",
       "      <th>Naphthalene-VFlag</th>\n",
       "      <th>Dodecane</th>\n",
       "      <th>Dodecane-MDL</th>\n",
       "      <th>Dodecane-VFlag</th>\n",
       "      <th>Hexachlorobutadiene</th>\n",
       "      <th>Hexachlorobutadiene-MDL</th>\n",
       "      <th>Hexachlorobutadiene-VFlag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40901</td>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>R</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.0</td>\n",
       "      <td>M1</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>M1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40901</td>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>R</td>\n",
       "      <td>0.269087</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.290962</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.764861</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021826</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017633</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40901</td>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>R</td>\n",
       "      <td>0.573501</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432543</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.541279</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027864</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40901</td>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>R</td>\n",
       "      <td>0.504552</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.392287</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.563230</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023531</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009625</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40901</td>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>R</td>\n",
       "      <td>0.200371</td>\n",
       "      <td>0.03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297843</td>\n",
       "      <td>0.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.475414</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022652</td>\n",
       "      <td>0.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010279</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005572</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 330 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   NAPS ID Sampling Date Sample Type    Ethylene  Ethylene-MDL Ethylene-VFlag  \\\n",
       "0    40901    2020-01-04           R -999.000000       -999.00             M1   \n",
       "1    40901    2020-01-10           R    0.269087          0.03            NaN   \n",
       "2    40901    2020-01-16           R    0.573501          0.03            NaN   \n",
       "3    40901    2020-01-22           R    0.504552          0.03            NaN   \n",
       "4    40901    2020-01-28           R    0.200371          0.03            NaN   \n",
       "\n",
       "    Acetylene  Acetylene-MDL Acetylene-VFlag      Ethane  ...  \\\n",
       "0 -999.000000        -999.00              M1 -999.000000  ...   \n",
       "1    0.290962           0.01             NaN    2.764861  ...   \n",
       "2    0.432543           0.01             NaN    4.541279  ...   \n",
       "3    0.392287           0.01             NaN    2.563230  ...   \n",
       "4    0.297843           0.01             NaN    2.475414  ...   \n",
       "\n",
       "   1,2,4-Trichlorobenzene-VFlag Naphthalene  Naphthalene-MDL  \\\n",
       "0                            M1 -999.000000          -999.00   \n",
       "1                           NaN    0.021826             0.07   \n",
       "2                           NaN    0.027864             0.07   \n",
       "3                           NaN    0.023531             0.07   \n",
       "4                           NaN    0.022652             0.07   \n",
       "\n",
       "   Naphthalene-VFlag    Dodecane  Dodecane-MDL  Dodecane-VFlag  \\\n",
       "0                 M1 -999.000000        -999.0              M1   \n",
       "1                NaN    0.017633           0.1             NaN   \n",
       "2                NaN    0.015945           0.1             NaN   \n",
       "3                NaN    0.009625           0.1             NaN   \n",
       "4                NaN    0.010279           0.1             NaN   \n",
       "\n",
       "  Hexachlorobutadiene  Hexachlorobutadiene-MDL  Hexachlorobutadiene-VFlag  \n",
       "0         -999.000000                  -999.00                         M1  \n",
       "1            0.002848                     0.06                        NaN  \n",
       "2            0.002526                     0.06                        NaN  \n",
       "3            0.002116                     0.06                        NaN  \n",
       "4            0.005572                     0.06                        NaN  \n",
       "\n",
       "[5 rows x 330 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filepath = pick_random_file('data', ignore_list)\n",
    "extension = filepath.split('.')[-1]\n",
    "\n",
    "if extension == 'xls':\n",
    "    header, date_column, sheet_name = how_many_xls_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "    workbook = xlrd.open_workbook(filepath, encoding_override='ISO-8859-1')\n",
    "    dataframe = pd.read_excel(workbook, header=header, sheet_name=sheet_name, engine='xlrd')\n",
    "    df = parse_dates(dataframe, date_column=date_column)\n",
    "elif extension == 'xlsx':\n",
    "    header, date_column, sheet_name = how_many_xlsx_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "    df = parse_dates(pd.read_excel(filepath, header=header, sheet_name=sheet_name), date_column=date_column)\n",
    "elif extension == 'csv':\n",
    "    header, date_column = how_many_csv_rows_to_skip(filepath, ['Compounds', 'Sampling Date'])\n",
    "    df = parse_dates(csv_to_pandas(filepath), date_column=date_column)\n",
    "\n",
    "display(df.dtypes)\n",
    "display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
